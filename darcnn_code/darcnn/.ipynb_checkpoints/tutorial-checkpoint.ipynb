{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch, torchvision\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import h5py\n",
    "import collections\n",
    "import os\n",
    "import pycocotools\n",
    "import sys \n",
    "import json\n",
    "import pickle\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.ndimage.measurements import label\n",
    "import mrcfile\n",
    "import skimage.io\n",
    "import skimage.morphology\n",
    "\n",
    "import detectron2\n",
    "from detectron2.utils.logger import setup_logger\n",
    "setup_logger()\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.engine import DefaultPredictor\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.utils.visualizer import Visualizer\n",
    "from detectron2.data import MetadataCatalog\n",
    "from detectron2.structures import BoxMode\n",
    "from detectron2.data import datasets\n",
    "from detectron2.data import DatasetCatalog, MetadataCatalog\n",
    "from detectron2.engine import DefaultTrainer\n",
    "from detectron2.utils.visualizer import ColorMode\n",
    "from detectron2.structures import Boxes, ImageList, Instances\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "from detectron2.modeling import build_model\n",
    "\n",
    "import sys\n",
    "sys.path.append('../dataset_and_eval')\n",
    "import eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First stage feature adaptation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cryo_dataset_dict = pickle.load(open('/pasteur/data/darcnn_dataset/datadicts/bbbc_unlabelled_dict.p', 'rb'))\n",
    "coco_dataset_dict = pickle.load(open('/pasteur/u/joycj/darcnn/coco/coco_dict.p', 'rb'))\n",
    "print(len(cryo_dataset_dict))\n",
    "print(len(coco_dataset_dict))\n",
    "\n",
    "joint_dataset_dict = []\n",
    "for i in range(9749):\n",
    "    idx = random.randint(0, 9749-1)\n",
    "    joint_dataset_dict.append(coco_dataset_dict[idx])\n",
    "    joint_dataset_dict.append(cryo_dataset_dict[idx])\n",
    "print(len(joint_dataset_dict))\n",
    "\n",
    "d = ['temp']   \n",
    "DatasetCatalog.register('train', lambda d=d: joint_dataset_dict)\n",
    "metadata = MetadataCatalog.get('train')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = '/pasteur/data/darcnn_dataset/checkpoints/coco/class_agnostic_maskrcnn/model_final.pth'\n",
    "#cfg.MODEL.WEIGHTS = '/pasteur/data/darcnn_dataset/checkpoints/bbbc/base_darcnn_fin/model_0000639.pth' # 639\n",
    "\n",
    "\n",
    "\n",
    "cfg.DATASETS.TRAIN = ('train',)\n",
    "cfg.DATASETS.TEST = ('train',)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.BASE_LR = 0.0001\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 20\n",
    "\n",
    "cfg.MODEL.META_ARCHITECTURE = 'DomainSeparationDARCNN'\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE = 0\n",
    "cfg.DATALOADER.ASPECT_RATIO_GROUPING = False\n",
    "    \n",
    "cfg.MODEL.FG = 10\n",
    "cfg.MODEL.BG = 10\n",
    "cfg.MODEL.SHARED_SIM = 1\n",
    "cfg.MODEL.CRYO_DIFF = 1\n",
    "cfg.MODEL.COCO_DIFF = 1\n",
    "    \n",
    "    \n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 50\n",
    "    \n",
    "cfg.OUTPUT_DIR = '/pasteur/data/darcnn_dataset/checkpoints/final/' + 'bbbc_darcnn' \n",
    "\n",
    "'''os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=False)\n",
    "trainer.train()'''\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/pasteur/data/darcnn_dataset/bbbc/10k_256/image800.png'\n",
    "img = cv2.imread(img)\n",
    "gt = '/pasteur/data/darcnn_dataset/bbbc/10k_256/mask800.png'\n",
    "gt = cv2.imread(gt)\n",
    "\n",
    "img = img[:256, :256]\n",
    "gt = gt[:256, :256]\n",
    "\n",
    "cfg.MODEL.WEIGHTS = '/pasteur/data/darcnn_dataset/checkpoints/final/bbbc_darcnn/model_0000399.pth'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.05\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.05\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "outputs = predictor(img)\n",
    "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20 , 20))\n",
    "ax1.imshow(gt)\n",
    "ax2.imshow(out.get_image())\n",
    "\n",
    "from_gt = out.get_image()\n",
    "from_gt_pred_masks = outputs['instances'].pred_masks.cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Second stage pseudolabelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bbox2(img):\n",
    "    rows = np.any(img, axis=1)\n",
    "    cols = np.any(img, axis=0)\n",
    "    rmin, rmax = np.where(rows)[0][[0, -1]]\n",
    "    cmin, cmax = np.where(cols)[0][[0, -1]]\n",
    "\n",
    "    return cmin, rmin, cmax, rmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tnbc_self_train_dataset_dicts(predictor):\n",
    "    tnbc_path = '/pasteur/data/darcnn_dataset/bbbc/10k_256/'\n",
    "\n",
    "    idx = 0\n",
    "    dataset_dicts = []\n",
    "    \n",
    "    for path in os.listdir(tnbc_path)[:1000]:\n",
    "        if 'image' not in path:\n",
    "            continue\n",
    "            \n",
    "        print(idx)\n",
    "        \n",
    "        record = {}\n",
    "            \n",
    "        curr_path = tnbc_path + path\n",
    "        record['file_name'] = curr_path\n",
    "            \n",
    "        record['image_id'] = idx\n",
    "        idx += 1\n",
    "            \n",
    "        record['height'] = 256\n",
    "        record['width'] = 256\n",
    "        \n",
    "        img = cv2.imread(curr_path)\n",
    "\n",
    "        img = cv2.GaussianBlur(img, (3,3), 0)\n",
    "        img = cv2.convertScaleAbs(img, alpha=2.5, beta=-250)\n",
    "        \n",
    "        outputs = predictor(img)\n",
    "        pred_masks = outputs['instances'].pred_masks.cpu().numpy()\n",
    "        scores = outputs['instances'].scores.cpu().numpy()\n",
    "        \n",
    "        record['confidence'] = scores\n",
    "        \n",
    "        objs = []\n",
    "        for i in range(pred_masks.shape[0]):\n",
    "            curr_obj = pred_masks[i, :, :]\n",
    "\n",
    "            try:\n",
    "                bbox = bbox2(curr_obj)\n",
    "            except:\n",
    "                plt.imshow(curr_obj)\n",
    "                continue\n",
    "                \n",
    "            curr_obj = curr_obj.astype(np.uint8)\n",
    "\n",
    "            obj = {\n",
    "                'bbox': bbox,\n",
    "                'bbox_mode': BoxMode.XYXY_ABS,\n",
    "                'segmentation': pycocotools.mask.encode(np.asarray(curr_obj, order=\"F\")),\n",
    "                'category_id': 1,\n",
    "            }\n",
    "            objs.append(obj)\n",
    "            \n",
    "        record['annotations'] = objs \n",
    "                \n",
    "        dataset_dicts.append(record) \n",
    "    \n",
    "    return dataset_dicts\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tnbc_dataset_dicts_predicted = pickle.load(open('/pasteur/data/darcnn_dataset/datadicts/bbbc_final.p', 'rb'))\n",
    "tnbc_dataset_dicts_predicted = get_tnbc_self_train_dataset_dicts(predictor)\n",
    "\n",
    "print(len(tnbc_dataset_dicts_predicted))\n",
    "pickle.dump(tnbc_dataset_dicts_predicted, open('/pasteur/data/darcnn_dataset/datadicts/bbbc_final.p', 'wb'))\n",
    "\n",
    "random.shuffle(tnbc_dataset_dicts_predicted)\n",
    "\n",
    "d = ['temp']   \n",
    "DatasetCatalog.register('tnbc', lambda d=d: tnbc_dataset_dicts_predicted)\n",
    "metadata = MetadataCatalog.get('tnbc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for d in random.sample(tnbc_dataset_dicts_predicted, 3):\n",
    "    img = cv2.imread(d[\"file_name\"])\n",
    "    visualizer = Visualizer(img[:, :, ::-1], metadata=metadata, scale=1.0)\n",
    "    out = visualizer.draw_dataset_dict(d)\n",
    "    plt.figure()\n",
    "    plt.imshow(out.get_image()[:, :, ::-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = get_cfg()\n",
    "cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n",
    "cfg.MODEL.WEIGHTS = '/pasteur/data/darcnn_dataset/checkpoints/final/bbbc_darcnn/model_0000299.pth'\n",
    "\n",
    "cfg.DATASETS.TRAIN = ('tnbc',)\n",
    "cfg.DATASETS.TEST = ('tnbc',)\n",
    "cfg.DATALOADER.NUM_WORKERS = 1\n",
    "\n",
    "cfg.MODEL.FG = 10\n",
    "cfg.MODEL.BG = 10\n",
    "cfg.MODEL.SHARED_SIM = 1\n",
    "cfg.MODEL.CRYO_DIFF = 1\n",
    "cfg.MODEL.COCO_DIFF = 1\n",
    "\n",
    "cfg.SOLVER.BASE_LR = 0.0001 \n",
    "cfg.SOLVER.IMS_PER_BATCH = 4\n",
    "cfg.SOLVER.MAX_ITER = 3000\n",
    "\n",
    "cfg.MODEL.META_ARCHITECTURE = 'PseudolabelTargetOnlyDARCNN'\n",
    "cfg.DATALOADER.FILTER_EMPTY_ANNOTATIONS = False\n",
    "cfg.MODEL.ROI_KEYPOINT_HEAD.MIN_KEYPOINTS_PER_IMAGE = 0\n",
    "cfg.DATALOADER.ASPECT_RATIO_GROUPING = False\n",
    "cfg.INPUT.MASK_FORMAT = 'bitmask'\n",
    "\n",
    "cfg.SOLVER.CHECKPOINT_PERIOD = 20\n",
    "\n",
    "cfg.OUTPUT_DIR = '/pasteur/data/darcnn_dataset/checkpoints/final/bbbc_pseudolabel_no_aug'\n",
    "\n",
    "os.makedirs(cfg.OUTPUT_DIR, exist_ok=True)\n",
    "trainer = DefaultTrainer(cfg) \n",
    "trainer.resume_or_load(resume=True)\n",
    "trainer.train()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = '/pasteur/data/darcnn_dataset/bbbc/10k_256/image800.png'\n",
    "img = cv2.imread(img)\n",
    "gt = '/pasteur/data/darcnn_dataset/bbbc/10k_256/mask800.png'\n",
    "gt = cv2.imread(gt)\n",
    "\n",
    "img = img[:256, :256]\n",
    "gt = gt[:256, :256]\n",
    "\n",
    "cfg.MODEL.WEIGHTS = '/pasteur/data/darcnn_dataset/checkpoints/final/bbbc_pseudolabel/model_0000839.pth'\n",
    "\n",
    "cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.06 # 0.07\n",
    "cfg.MODEL.ROI_HEADS.NMS_THRESH_TEST = 0.05\n",
    "cfg.TEST.DETECTIONS_PER_IMAGE = 200\n",
    "cfg.MODEL.RPN.POST_NMS_TOPK_TEST = 1000\n",
    "\n",
    "predictor = DefaultPredictor(cfg)\n",
    "\n",
    "outputs = predictor(img)\n",
    "\n",
    "v = Visualizer(img[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.0)\n",
    "out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n",
    "\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20 , 20))\n",
    "ax1.imshow(gt)\n",
    "ax2.imshow(out.get_image())\n",
    "predicted = out.get_image()\n",
    "\n",
    "from_gt = out.get_image()\n",
    "from_gt_pred_masks = outputs['instances'].pred_masks.cpu().numpy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
